{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10c908a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import poisson\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn import cluster\n",
    "from scipy.stats import poisson\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184ba44e",
   "metadata": {},
   "source": [
    "# Read the data sequence\n",
    "\n",
    "We are given a data sequence consisting on number of earthquakes for each year between the years 1900 and 2006."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4d4c007",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_seq = []\n",
    "observation_seq = []\n",
    "f = open('earthquakes.txt','r')\n",
    "line = f.readline()\n",
    "while line:\n",
    "    line=line.rstrip().split('\t')\n",
    "    state_seq.append(int(line[0]))\n",
    "    observation_seq.append(int(line[1]))\n",
    "    line = f.readline()\n",
    "    \n",
    "state_seq = np.array(state_seq)\n",
    "observation_seq = np.array(observation_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bb81247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# the histogram of the data\n",
    "plt.bar(state_seq, observation_seq, color='lightblue')\n",
    "\n",
    "ax.set_xlabel('year')\n",
    "ax.set_ylabel('earthquakes')\n",
    "ax.set_title(r'Earthquakes between the years 1900 and 2006')\n",
    "\n",
    "# Tweak spacing to prevent clipping of ylabel\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d043768e",
   "metadata": {},
   "source": [
    "# Direct maximization of the likelihood\n",
    "\n",
    "The likelihood of a mixture model with m components is given, for both discrete and continuous cases by:\n",
    "\n",
    "\\begin{equation}\n",
    "\n",
    "L(\\theta_1,...,\\theta_m,\\delta_1,...,\\delta_m|x_1,...,x_n) = \\prod_{j=1}^n\\sum_{i=1}^m\\delta_ip_i(x_j,\\theta_i)\n",
    "\n",
    "\\end{equation}\n",
    "- Where $\\theta_1,...,\\theta_m$ are the paramenter vectors for the component distributions,\n",
    "- $\\delta_1,...,\\delta_m$ are the mixing parameters, totalling 1,\n",
    "- $x_1,...,x_n$ the $n$ observations.\n",
    "Supose $m = 2$, and the two components are Poisson-distributed, which means $\\lambda_1$ and $\\lambda_2$. Let $\\delta_1$ and $\\delta_2$ be the mixing parameters (with $\\delta_1+\\delta_2 =1$). The mixture distribution $p$ is then given by:\n",
    "\\begin{equation}\n",
    "p(x) = \\delta_1\\frac{\\lambda^x_1e^{-\\lambda_1}}{x!}+\\delta_2\\frac{\\lambda^x_2e^{-\\lambda_2}}{x!}\n",
    "\\end{equation}\n",
    "Since $\\delta_2 = 1 - \\delta_1$, there are only three parameters to be estimated: $\\lambda_1,\\lambda_2$ and $\\delta_1$. The likelihood is:\n",
    "\\begin{equation}\n",
    "L(\\lambda_1,\\lambda_2,\\delta_1|x_1,...,x_n) = \\prod_{i=1}^n\\delta_1\\frac{\\lambda^x_1e^{-\\lambda_1}}{x_i!}+(1-\\delta_1)\\frac{\\lambda^x_2e^{-\\lambda_2}}{x_i!}\n",
    "\\end{equation}\n",
    "\n",
    "The analytic maximization of $L$ with respect to $\\lambda_1,\\lambda_2$ and $\\delta_1$ would be awkward, as $L$ is the product of $n$ factors, each of which is a sum. Therefore parameter estimation is more conveniently carried out by direct numerical maximization of the likelihood or its logarithm.\n",
    "However, the parameters $\\delta$ and $\\lambda$ are constrained by $\\sum^m_{i=1}\\delta_i = 1$ and (for i=1,...,$m$)$\\delta_i>0$ and $\\lambda_i>0$. It is therefore necessary to reparametrize when using an unconstrained optimizer.\n",
    "One possibility is to maximize the likelihood with respect to the 2m-1 unconstrained 'working parameters'.\n",
    "\\begin{equation}\n",
    "\\eta_i = log\\lambda_i \\; (i=1,...,m)\n",
    "\\end{equation}\n",
    "and\n",
    "\\begin{equation}\n",
    "\\tau_i = log\\left( \\frac{\\delta_i}{1-\\sum^m_{j=2}\\delta_j}\\right) \\; (i=2,...,m)\n",
    "\\end{equation}\n",
    "and\n",
    "\\begin{equation}\n",
    "\\delta_1 = 1 - \\sum^m_{j=2}\\delta_i\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c77bd2",
   "metadata": {},
   "source": [
    "## Hidden Markov Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b51c29e",
   "metadata": {},
   "source": [
    "### The likelihood\n",
    "\n",
    "Consider a HMM in general with observation sequence $x_1,x_2,...,x_T$. The probability $L_T$ of observed that sequence is calculated under an m-state HMM which has initial distribution $\\delta$ and transition probability matrix $\\daleth$ for the markov chainm and state-dependent probability (density) functions $p_i$.\n",
    "\n",
    "The likelihood is then given by:\n",
    "\\begin{equation}\n",
    "L_T = \\delta P(x_1)\\daleth P(x_2)...\\daleth P(x_T)1'\n",
    "\\end{equation}\n",
    "If $\\delta$, the distribution of $C_1$, is the stationary distribution of the Markov chain, then in addition:\n",
    "\\begin{equation}\n",
    "L_T = \\delta\\daleth P(x_1)\\daleth P(x_2)...\\daleth P(x_T)1'\n",
    "\\end{equation}\n",
    "\n",
    "#### The forward algorithm\n",
    "The forward algorithm is a recursive computation of the likelihood, which is computationally much more efficient than the brute-force summation. This computational inexpensiveness is the key feature of HMMs.\n",
    "\n",
    "We state the forward algorithm by the vector $\\alpha_t$, for $t=1,2,...,T$ by:\n",
    "\\begin{equation}\n",
    "\\alpha_t = \\delta P(x_1)\\daleth P(x_2)...\\daleth P(x_t) = \\delta P(x_1)\\prod_{s=2}^t\\daleth P(x_s)\n",
    "\\end{equation}\n",
    "So then the likelihood:\n",
    "\\begin{equation}\n",
    "L_T = \\alpha_T1'\n",
    "\\end{equation}\n",
    "and:\n",
    "\\begin{equation}\n",
    "\\alpha_t = \\alpha_{t-1}\\daleth P(x_t) \\;  for \\; t\\ge 2\n",
    "\\end{equation}\n",
    "\n",
    "The elements of the vector $\\alpha_t$ are referred as **forward probabilities**.\n",
    "The number of operations is of order Tm^2. But there are several numerical problems to overcome:\n",
    "\n",
    "- **Numerical (over/under)flow:** for discrete state-dependent distributions, the elements of $\\alpha_t$, being made up of products of probabilities, become progressively smaller as $t$ increases. For the continous case, it reaches $\\inf$. The solution is the same for over and underflow: scaling the vector $\\alpha_t$ at eacht time $t$ so that its elemets sum up to 1.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\phi_t = \\alpha_t/w_t, \\; with \\; w_t = \\sum_i\\alpha_t(i)\n",
    "\\end{equation}\n",
    "Hence,\n",
    "\\begin{equation}\n",
    "logL_T = \\sum_{t=1}^Tlog(w_t/w_{t-1}) = \\sum_{t=1}^Tlog(\\phi_{t-1}\\daleth P(x_t)1')\n",
    "\\end{equation}\n",
    "- **Constraints:** we can have constrains that apply to the parameters of the state-dependent distributions, and to the parameters of the Markov chain. The relevant constrains for a Poisson HMM are:\n",
    "    - the means $\\lambda_i$ of the state-dependent distributions must be non-negative. This is easily solved by defining $\\eta_i = \\log\\lambda_i$\n",
    "   \n",
    "    - The rows of the transition probability matrix $\\daleth$ must sum up to one, with all parameters $\\gamma_{ij}$ non-negative.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98846603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_diag(x):\n",
    "    x_no_diag = np.ndarray.flatten(x)\n",
    "    x_no_diag = np.delete(x_no_diag, range(0, len(x_no_diag), len(x) + 1), 0)\n",
    "    x_no_diag = x_no_diag.reshape(len(x), len(x) - 1)\n",
    "    return x_no_diag\n",
    "def add_zero_diag(a):    \n",
    "    b = np.zeros((a.shape[0], a.shape[1]+1), dtype=a.dtype)\n",
    "    i = np.arange(b.shape[0])\n",
    "    j = np.arange(b.shape[1])\n",
    "    b[np.not_equal.outer(i, j)] = a.flat\n",
    "    return b\n",
    "\n",
    "\n",
    "def pn2pw(m,lmbda,gamma,delta=None,stationary=True):\n",
    "    '''natural parameters to working parametes'''        \n",
    "    # contraint for lambda\n",
    "    tlambda = np.log(lmbda)\n",
    "    if m == 1:\n",
    "        return tlambda\n",
    "    # contraint for transition probability matrix\n",
    "    tgamma = np.log(gamma/np.diag(gamma))\n",
    "    # discard diagonal elemets from the transformed vector\n",
    "    tau = remove_diag(tgamma)\n",
    "    if stationary:\n",
    "        tdelta = None\n",
    "    else:\n",
    "        tdelta = np.log(delta[-1]/delta[1])\n",
    "        \n",
    "    return tlambda,tau,tdelta\n",
    "    \n",
    "def pw2pn(m,tlambda,tau,tdelta,stationary=True):\n",
    "    ''' working to natural parameters'''\n",
    "    lmbda = np.exp(tlambda)\n",
    "        \n",
    "    # operations on tau to get off-diagonal elements of gamma\n",
    "    element_exp = np.exp(tau)\n",
    "    sumexp =1/(np.sum(element_exp,axis=1)+1).reshape((m,1))\n",
    "    gamma = element_exp*sumexp\n",
    "    # add diagonal elements to gamma\n",
    "    gamma = add_zero_diag(gamma)\n",
    "    gamma += np.diagflat(1-np.sum(gamma,axis=1))# fill diagonal making elements sum up to 1       \n",
    "    \n",
    "    if stationary:\n",
    "        delta = np.linalg.solve(np.identity(m)-gamma+np.ones((m,m)),np.ones((1,m)).T)\n",
    "    else:\n",
    "        edelta = np.exp(tdelta)\n",
    "        delta = edelta/np.sum(edelta,axis=1)\n",
    "            \n",
    "    return lmbda,gamma,delta\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce63fa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson_mllk(vector,x,m,stationary):\n",
    "    ''' vector has to be a 1D vector '''\n",
    "    # read stored values\n",
    "    # iterate as start+cellsize*index\n",
    "    tlambda = vector[0:m].astype(float)\n",
    "    tau = vector[m:m+m].astype(float)\n",
    "    tau = tau.reshape((m,m-1))\n",
    "    tdelta = vector[-1]\n",
    "    if tdelta==0: tdelta = None\n",
    "    else: tdelta = vector[-m]\n",
    "\n",
    "\n",
    "    # if we only have 1 state\n",
    "    if m==1: return (-np.sum(poisson.pmf(k=x,mu=np.exp(tlambda))))\n",
    "\n",
    "    # get natural parameters\n",
    "    lmbda,gamma,delta = pw2pn(m,tlambda,tau,tdelta,stationary=stationary)\n",
    "\n",
    "\n",
    "    # for initial value\n",
    "    alpha = delta.T * poisson.pmf(k=x[0],mu=lmbda)\n",
    "    sum_alpha = np.sum(alpha)\n",
    "    lscale = np.log(sum_alpha)\n",
    "    alpha = alpha/sum_alpha  \n",
    "\n",
    "    # for the rest of the values    \n",
    "    for i in range (len(x)):\n",
    "        alpha = alpha*np.matmul(gamma, poisson.pmf(k=x[i],mu=lmbda)) \n",
    "        sum_alpha = np.sum(alpha)\n",
    "        lscale += np.log(sum_alpha)\n",
    "        alpha = alpha/sum_alpha\n",
    "\n",
    "        \n",
    "    return -lscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poisson maximum likelihood estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f96bfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson_mle(x,m,lambda_ini,gamma_ini,delta_ini=None,stationary=True):\n",
    "    ''' maximum likelihood estimation for a poisson distribution,\n",
    "    given starting values for natural parameters'''\n",
    "    # convert params to working parameters\n",
    "    tlambda,tau,tdelta = pn2pw(m,lambda_ini,gamma_ini,delta_ini,stationary)\n",
    "    # store in a vector of params to be optimized\n",
    "    if tdelta == None: tdelta = 0\n",
    "    partvec = np.hstack([tlambda.flatten(),tau.flatten(),tdelta])\n",
    "    print('initial vector:', partvec)\n",
    "    print('initial log likelihood:',poisson_mllk(partvec,x,m,stationary))\n",
    "    # minimize log likelihood\n",
    "    min_log = minimize(poisson_mllk,partvec,args = (x,m,stationary),method='CG', tol=1e-3)\n",
    "    print('after minimization',min_log)\n",
    "    # convert params from minimization to natural parameters\n",
    "    tdelta = min_log.x[-1]\n",
    "    if tdelta==0: tdelta = None\n",
    "    else: tdelta = vector[-m]\n",
    "    lmbda,gamma,delta = pw2pn(m,min_log.x[0:m],min_log.x[m:m+m],tdelta,stationary=stationary)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a 2-state Hidden Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "tamil-warrior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial vector: [ 2.7080502   3.21887582 -2.19722458 -2.19722458  0.        ]\n",
      "initial log likelihood: 384.12117497795634\n",
      "after minimization      fun: 363.51733491349694\n",
      "     jac: array([-2.63214111e-04,  3.05175781e-05, -6.10351562e-05,  7.62939453e-06,\n",
      "        0.00000000e+00])\n",
      " message: 'Optimization terminated successfully.'\n",
      "    nfev: 414\n",
      "     nit: 36\n",
      "    njev: 69\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([ 2.74919961,  3.28187857, -0.67496134, -2.1972244 ,  0.        ])\n"
     ]
    }
   ],
   "source": [
    "m = 2\n",
    "lambda_ini = np.array([15,25])\n",
    "gamma_ini = np.array([[0.9,0.1],[0.1,0.9]])\n",
    "poisson_mle(observation_seq,m,lambda_ini,gamma_ini,None,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c5a37e",
   "metadata": {},
   "source": [
    "# The EM algorithm \n",
    "\n",
    "## for a Mixture model of 3 Poisson distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b810d600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import poisson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1d55ae",
   "metadata": {},
   "source": [
    "Assuming that the earthquakes data is distributed according to a Poisson mixture model, here I will implement the EM algorithm to learn the probability parameters.\n",
    "\n",
    "The data notation is as follows:\n",
    "\n",
    "   - The full data $(X,Y)$ corresponding to periods with high and low amounts of earthquakes.\n",
    "   - The observed data $ Y = y_i, i= 1,...,n$ corresponds to the number of earthquakes.\n",
    "   - The missing data is \"in what period we are for the amount of earthquakes\", $X = (x_1,...,x_n) \\in \\{1,2,3\\}^n$\n",
    "   - The parameters $\\theta = \\{\\lambda_1,\\lambda_2,\\lambda_3,\\delta_1,\\delta_2,\\delta_3\\}$\n",
    "   \n",
    "The EM algorithm converges towards a local maximum of the data log-likelihood function. It starts with an initializing value $\\theta^0$, which is updated by an iterative procedure of two steps: the E step and the M step.\n",
    "\n",
    "Considering a Poisson mixture of three components like we will do in this example, we have three disjoint events, with $\\delta_k$ the probability of being in each of the three classes.\n",
    "\\begin{equation}\n",
    "\\delta_1 = P(x_i=1), \\delta_2 = P(x_i=2), \\delta_3 = P(x_i=3) = 1-\\delta_1-\\delta_2\n",
    "\\end{equation}\n",
    "The probability of having our given data given that we are in a class k is given by:\n",
    "\\begin{equation}\n",
    "y_i|x_i = 1∼Po(\\lambda_1), y_i|x_i = 2∼Po(\\lambda_2), y_i|x_i = 3∼Po(\\lambda_3)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70fab01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = state_seq\n",
    "Y = observation_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd5bc7f",
   "metadata": {},
   "source": [
    "### The E step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf99ea5",
   "metadata": {},
   "source": [
    "Since the complete log-likelihood is unknown, we use the posterior to evaluate the expectation of the complete data log-likelihood.\n",
    "\n",
    "Computes the conditional probability that the hidden state $x_i=1$\n",
    "\\begin{equation}\n",
    "P(X_i = 1 | Y_i = y_i) = \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a52b38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_step(delta,lmbda,data):\n",
    "    # Handling errors\n",
    "    if np.sum(delta)!=1:\n",
    "        raise ValueError('Delta is not a probability distribution (the values dont sum up to 1)')\n",
    "    # Conditional probability of delta given y\n",
    "    delta_prob = 0\n",
    "    for i in range (len(lmbda)):\n",
    "        delta_prob += delta[i] * poisson.pmf(k=data,mu=lmbda[i])    \n",
    "        \n",
    "    # Conditional probability of each class given data\n",
    "    # Probability of mixture 1 to m\n",
    "    prob = []\n",
    "    for i in range (len(lmbda)-1):\n",
    "        prob.append(delta[i] * poisson.pmf(data,lmbda[i])/delta_prob)\n",
    "      \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e089aa",
   "metadata": {},
   "source": [
    "### The M step\n",
    "\n",
    "Updates the probability parameters so that they maximize the expected value of the data log likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d1b7e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_step(prob ,delta, lmbda, data):    \n",
    "    n_i = [] # number of times we expect to see each mixture, from xi = 1 to xi = m\n",
    "    s_i = [] # sum of data points in the indicator components\n",
    "    for i in range(len(lmbda)-1):\n",
    "        n_i.append(np.sum(prob[i]))\n",
    "        s_i.append(np.sum(data*prob[i]))\n",
    "    n_i.append(len(data)-np.sum(n_i))\n",
    "    s_i.append(np.sum(data)-np.sum(s_i))\n",
    "    \n",
    "    \n",
    "    delta = np.asarray(n_i)/len(data)\n",
    "    delta = np.append(delta,1-sum(delta))\n",
    "\n",
    "        \n",
    "    lmbda = np.divide(np.asarray(s_i),np.asarray(n_i))\n",
    "\n",
    "    \n",
    "    \n",
    "    return delta, lmbda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea8b06c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EM_algorithm(delta,lmbda,data,iterations):\n",
    "    prob = 0.\n",
    "    for i in range(iterations):\n",
    "        prob = E_step(delta,lmbda,Y)\n",
    "        delta,lmbda    = M_step(prob, delta,lmbda,Y)\n",
    "        \n",
    "    return delta,lmbda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8384eb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.27716677, 0.59308916, 0.12974408, 0.        ]),\n",
       " array([12.73203817, 19.78158473, 31.62645129]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = observation_seq\n",
    "delta = np.array([0.5,0.4,0.1])\n",
    "lmbda = np.array([10.,20.,30.])\n",
    "EM_algorithm(delta,lmbda, Y, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-documentary",
   "metadata": {},
   "source": [
    "Function for a Poisson Maximum Likelihood estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "functioning-matthew",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.3, 0.7, 0.8, 1.9, 1.2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.00000002, 1.00000002, 1.00000007, 1.00000015, 1.00000028])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import minimize, rosen, rosen_der\n",
    "x0 = [1.3, 0.7, 0.8, 1.9, 1.2]\n",
    "print(x0)\n",
    "res = minimize(rosen, x0, method='Nelder-Mead', tol=1e-6)\n",
    "res.x"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "723f24fb6b988431f975955e352dd8a1539263d396f5801e60cea3e9e9d17e92"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('cv': virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
