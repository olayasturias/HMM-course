{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10c908a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import poisson\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn import cluster\n",
    "from scipy.stats import poisson\n",
    "from hmmlearn.base import _BaseHMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a8e9f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(A, axis=None):\n",
    "    \"\"\"Normalize the input array so that it sums to 1.\n",
    "    Parameters\n",
    "    ----------\n",
    "    A: array, shape (n_samples, n_features)\n",
    "        Non-normalized input data.\n",
    "    axis: int\n",
    "        Dimension along which normalization is performed.\n",
    "    Returns\n",
    "    -------\n",
    "    normalized_A: array, shape (n_samples, n_features)\n",
    "        A with values normalized (summing to 1) along the prescribed axis\n",
    "    WARNING: Modifies the array inplace.\n",
    "    \"\"\"\n",
    "    A += np.finfo(float).eps\n",
    "    Asum = A.sum(axis)\n",
    "    if axis and A.ndim > 1:\n",
    "        # Make sure we don't divide by zero.\n",
    "        Asum[Asum == 0] = 1\n",
    "        shape = list(A.shape)\n",
    "        shape[axis] = 1\n",
    "        Asum.shape = shape\n",
    "    A /= Asum\n",
    "    # TODO: should return nothing, since the operation is inplace.\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ea07cb",
   "metadata": {},
   "source": [
    "# Implement the Hidden Markov Model with Poisson emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1c3e35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "__all__ = ['GMMHMM',\n",
    "           'GaussianHMM',\n",
    "           'MultinomialHMM']\n",
    "\n",
    "NEGINF = -np.inf\n",
    "\n",
    "\n",
    "class PoissonHMM(_BaseHMM):\n",
    "    \"\"\"Hidden Markov Model with Poisson emissions\n",
    "    Representation of a hidden Markov model probability distribution.\n",
    "    This class allows for easy evaluation of, sampling from, and\n",
    "    maximum-likelihood estimation of the parameters of a HMM.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_components=1, startprob=None,\n",
    "                 transmat=None, startprob_prior=None, transmat_prior=None,\n",
    "                 algorithm=\"viterbi\", means_prior=0, \n",
    "                 random_state=None, n_iter=10, thresh=1e-2,\n",
    "                 params=string.ascii_letters,\n",
    "                 init_params=string.ascii_letters):\n",
    "        _BaseHMM.__init__(self, n_components, startprob, transmat,\n",
    "                          startprob_prior=startprob_prior,\n",
    "                          transmat_prior=transmat_prior, algorithm=algorithm,\n",
    "                          random_state=random_state, n_iter=n_iter,\n",
    "                          thresh=thresh, params=params,\n",
    "                          init_params=init_params)\n",
    "        self.means_prior = means_prior\n",
    " \n",
    "\n",
    "    def _get_means(self):\n",
    "        \"\"\"lambda parameters for each state.\"\"\"\n",
    "        return self._means_\n",
    "\n",
    "\n",
    "    def _set_means(self, means):\n",
    "        means = np.asarray(means)\n",
    "        if (hasattr(self, 'n_features')\n",
    "                and means.shape != (self.n_components, self.n_features)):\n",
    "            raise ValueError('means must have shape '\n",
    "                             '(n_components, n_features)')\n",
    "        self._means_ = means.copy()\n",
    "        self.n_features = self._means_.shape[1]\n",
    "\n",
    "    \n",
    "    means_ = property(_get_means, _set_means)\n",
    "\n",
    "\n",
    "    def _compute_log_likelihood(self, obs):\n",
    "        all_obs = np.concatenate(obs)\n",
    "        logp = np.empty([1, len(all_obs)])\n",
    "\n",
    "        for lam in self._means_:\n",
    "            p = poisson.logpmf(all_obs, lam)\n",
    "            logp = np.vstack((logp,p))\n",
    "        logp = logp[1:,:]\n",
    "\n",
    "\n",
    "        return logp.T \n",
    "\n",
    "\n",
    "\n",
    "    def _init(self, obs, params='stmc'):\n",
    "        super(PoissonHMM, self)._init(obs, params=params)\n",
    "\n",
    "        all_obs = np.concatenate(obs)\n",
    "        _, n_features = all_obs.shape\n",
    "\n",
    "        if hasattr(self, 'n_features') and self.n_features != n_features:\n",
    "            raise ValueError('Unexpected number of dimensions, got %s but '\n",
    "                             'expected %s' % (n_features, self.n_features))\n",
    "\n",
    "        self.n_features = n_features\n",
    "        if 'm' in params:\n",
    "            self._means_ = self.means_prior\n",
    "\n",
    "                     \n",
    "\n",
    "    def _initialize_sufficient_statistics(self):\n",
    "        stats = super(PoissonHMM, self)._initialize_sufficient_statistics()\n",
    "\n",
    "        stats['post'] = np.zeros(self.n_components)\n",
    "        stats['obs'] = np.zeros((self.n_components, self.n_features)) # expected number in state\n",
    "\n",
    "        return stats\n",
    "\n",
    "    def _accumulate_sufficient_statistics(self, stats, obs, framelogprob,\n",
    "                                          posteriors, fwdlattice, bwdlattice,\n",
    "                                          params):\n",
    "\n",
    "        super(PoissonHMM, self)._accumulate_sufficient_statistics(\n",
    "            stats, obs, framelogprob, posteriors, fwdlattice, bwdlattice,\n",
    "            params)\n",
    "\n",
    "        if 'm' in params or 'c' in params:\n",
    "            stats['post'] += posteriors.sum(axis=0)\n",
    "            stats['obs'] += np.dot(posteriors.T, obs)\n",
    "\n",
    "    def _do_mstep(self, stats, params):\n",
    "        super(PoissonHMM, self)._do_mstep(stats, params)\n",
    "\n",
    "        denom = stats['post'][:, np.newaxis]\n",
    "        if 'm' in params:\n",
    "            self._means_ = ((stats['obs']) / (denom))\n",
    "        self._means_ = np.maximum(self._means_, np.array([[self.means_prior[0]],[self.means_prior[0]],[self.means_prior[0]]]))\n",
    "\n",
    "\n",
    "\n",
    "    def fit(self, obs):\n",
    "        \"\"\"Estimate model parameters.\n",
    "        An initialization step is performed before entering the EM\n",
    "        algorithm. If you want to avoid this step, pass proper\n",
    "        ``init_params`` keyword argument to estimator's constructor.\n",
    "        Parameters\n",
    "        ----------\n",
    "        obs : list\n",
    "            List of array-like observation sequences, each of which\n",
    "            has shape (n_i, n_features), where n_i is the length of\n",
    "            the i_th observation.\n",
    "        \"\"\"\n",
    "        \n",
    "        return super(PoissonHMM, self).fit(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0aca11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb082f64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "184ba44e",
   "metadata": {},
   "source": [
    "# Read the data sequence\n",
    "\n",
    "We are given a data sequence consisting on number of earthquakes for each year between the years 1900 and 2006."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4d4c007",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_seq = []\n",
    "observation_seq = []\n",
    "f = open('earthquakes.txt','r')\n",
    "line = f.readline()\n",
    "while line:\n",
    "    line=line.rstrip().split('\t')\n",
    "    state_seq.append(int(line[0]))\n",
    "    observation_seq.append(int(line[1]))\n",
    "    line = f.readline()\n",
    "    \n",
    "state_seq = np.array(state_seq)\n",
    "observation_seq = np.array(observation_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bb81247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# the histogram of the data\n",
    "plt.bar(state_seq, observation_seq, color='lightblue')\n",
    "\n",
    "ax.set_xlabel('year')\n",
    "ax.set_ylabel('earthquakes')\n",
    "ax.set_title(r'Earthquakes between the years 1900 and 2006')\n",
    "\n",
    "# Tweak spacing to prevent clipping of ylabel\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d043768e",
   "metadata": {},
   "source": [
    "# Direct maximization of the likelihood\n",
    "\n",
    "The likelihood of a mixture model with m components is given, for both discrete and continuous cases by:\n",
    "\\begin{equation}\n",
    "L(\\theta_1,...,\\theta_m,\\delta_1,...,\\delta_m|x_1,...,x_n) = \\prod_{j=1}^n\\sum_{i=1}^m\\delta_ip_i(x_j,\\theta_i)\n",
    "\\end{equation}\n",
    "- Where $\\theta_1,...,\\theta_m$ are the paramenter vectors for the component distributions,\n",
    "- $\\delta_1,...,\\delta_m$ are the mixing parameters, totalling 1,\n",
    "- $x_1,...,x_n$ the $n$ observations.\n",
    "Supose $m = 2$, and the two components are Poisson-distributed, which means $\\lambda_1$ and $\\lambda_2$. Let $\\delta_1$ and $\\delta_2$ be the mixing parameters (with $\\delta_1+\\delta_2 =1$). The mixture distribution $p$ is then given by:\n",
    "\\begin{equation}\n",
    "p(x) = \\delta_1\\frac{\\lambda^x_1e^{-\\lambda_1}}{x!}+\\delta_2\\frac{\\lambda^x_2e^{-\\lambda_2}}{x!}\n",
    "\\end{equation}\n",
    "Since $\\delta_2 = 1 - \\delta_1$, there are only three parameters to be estimated: $\\lambda_1,\\lambda_2$ and $\\delta_1$. The likelihood is:\n",
    "\\begin{equation}\n",
    "L(\\lambda_1,\\lambda_2,\\delta_1|x_1,...,x_n) = \\prod_{i=1}^n\\delta_1\\frac{\\lambda^x_1e^{-\\lambda_1}}{x_i!}+(1-\\delta_1)\\frac{\\lambda^x_2e^{-\\lambda_2}}{x_i!}\n",
    "\\end{equation}\n",
    "\n",
    "The analytic maximization of $L$ with respect to $\\lambda_1,\\lambda_2$ and $\\delta_1$ would be awkward, as $L$ is the product of $n$ factors, each of which is a sum. Therefore parameter estimation is more conveniently carried out by direct numerical maximization of the likelihood or its logarithm.\n",
    "However, the parameters $\\delta$ and $\\lambda$ are constrained by $\\sum^m_{i=1}\\delta_i = 1$ and (for i=1,...,$m$)$\\delta_i>0$ and $\\lambda_i>0$. It is therefore necessary to reparametrize when using an unconstrained optimizer.\n",
    "One possibility is to maximize the likelihood with respect to the 2m-1 unconstrained 'working parameters'.\n",
    "\\begin{equation}\n",
    "\\eta_i = log\\lambda_i \\; (i=1,...,m)\n",
    "\\end{equation}\n",
    "and\n",
    "\\begin{equation}\n",
    "\\tau_i = log\\left( \\frac{\\delta_i}{1-\\sum^m_{j=2}\\delta_j}\\right) \\; (i=2,...,m)\n",
    "\\end{equation}\n",
    "and\n",
    "\\begin{equation}\n",
    "\\delta_1 = 1 - \\sum^m_{j=2}\\delta_i\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c77bd2",
   "metadata": {},
   "source": [
    "## Hidden Markov Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b51c29e",
   "metadata": {},
   "source": [
    "### The likelihood\n",
    "\n",
    "Consider a HMM in general with observation sequence $x_1,x_2,...,x_T$. The probability $L_T$ of observed that sequence is calculated under an m-state HMM which has initial distribution $\\delta$ and transition probability matrix $\\daleth$ for the markov chainm and state-dependent probability (density) functions $p_i$.\n",
    "\n",
    "The likelihood is then given by:\n",
    "\\begin{equation}\n",
    "L_T = \\delta P(x_1)\\daleth P(x_2)...\\daleth P(x_T)1'\n",
    "\\end{equation}\n",
    "If $\\delta$, the distribution of $C_1$, is the stationary distribution of the Markov chain, then in addition:\n",
    "\\begin{equation}\n",
    "L_T = \\delta\\daleth P(x_1)\\daleth P(x_2)...\\daleth P(x_T)1'\n",
    "\\end{equation}\n",
    "\n",
    "#### The forward algorithm\n",
    "The forward algorithm is a recursive computation of the likelihood, which is computationally much more efficient than the brute-force summation. This computational inexpensiveness is the key feature of HMMs.\n",
    "\n",
    "We state the forward algorithm by the vector $\\alpha_t$, for $t=1,2,...,T$ by:\n",
    "\\begin{equation}\n",
    "\\alpha_t = \\delta P(x_1)\\daleth P(x_2)...\\daleth P(x_t) = \\delta P(x_1)\\prod_{s=2}^t\\daleth P(x_s)\n",
    "\\end{equation}\n",
    "So then the likelihood:\n",
    "\\begin{equation}\n",
    "L_T = \\alpha_T1'\n",
    "\\end{equation}\n",
    "and:\n",
    "\\begin{equation}\n",
    "\\alpha_t = \\alpha_{t-1}\\daleth P(x_t) \\;  for \\; t\\ge 2\n",
    "\\end{equation}\n",
    "- **Numerical (over/under)flow:** for discrete state-dependent distributions, the elements of $\\alpha_t$, being made up of products of probabilities, become progressively smaller as $t$ increases. For the continous case, it reaches $\\inf$. The solution is the same for over and underflow: scaling the vector $\\alpha_t$ at eacht time $t$ so that its elemets sum up to 1.\n",
    "\n",
    "The elements of the vector $\\alpha_t$ are referred as **forward probabilities**.\n",
    "\n",
    "The number of operations is of order Tm^2. But there are several numerical problems to overcome:\n",
    "\n",
    "\\begin{equation}\n",
    "\\phi_t = \\alpha_t/w_t, \\; with \\; w_t = \\sum_i\\alpha_t(i)\n",
    "\\end{equation}\n",
    "Hence,\n",
    "\\begin{equation}\n",
    "logL_T = \\sum_{t=1}^Tlog(w_t/w_{t-1}) = \\sum_{t=1}^Tlog(\\phi_{t-1}\\daleth P(x_t)1')\n",
    "\\end{equation}\n",
    "- **Constraints:** we can have constrains that apply to the parameters of the state-dependent distributions, and to the parameters of the Markov chain. The relevant constrains for a Poisson HMM are:\n",
    "    - the means $\\lambda_i$ of the state-dependent distributions must be non-negative.\n",
    "    - The rows of the transition probability matrix $\\daleth$ must sum up to one, with all parameters $\\gamma_{ij}$ non-negative.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98846603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0a5e73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd78898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10c5a37e",
   "metadata": {},
   "source": [
    "# The EM algorithm \n",
    "\n",
    "## for a Mixture model of 3 Poisson distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b810d600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import poisson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1d55ae",
   "metadata": {},
   "source": [
    "Assuming that the earthquakes data is distributed according to a Poisson mixture model, here I will implement the EM algorithm to learn the probability parameters.\n",
    "\n",
    "The data notation is as follows:\n",
    "\n",
    "   - The full data $(X,Y)$ corresponding to periods with high and low amounts of earthquakes.\n",
    "   - The observed data $ Y = y_i, i= 1,...,n$ corresponds to the number of earthquakes.\n",
    "   - The missing data is \"in what period we are for the amount of earthquakes\", $X = (x_1,...,x_n) \\in \\{1,2,3\\}^n$\n",
    "   - The parameters $\\theta = \\{\\lambda_1,\\lambda_2,\\lambda_3,\\delta_1,\\delta_2,\\delta_3\\}$\n",
    "   \n",
    "The EM algorithm converges towards a local maximum of the data log-likelihood function. It starts with an initializing value $\\theta^0$, which is updated by an iterative procedure of two steps: the E step and the M step.\n",
    "\n",
    "Considering a Poisson mixture of three components like we will do in this example, we have three disjoint events, with $\\delta_k$ the probability of being in each of the three classes.\n",
    "\\begin{equation}\n",
    "\\delta_1 = P(x_i=1), \\delta_2 = P(x_i=2), \\delta_3 = P(x_i=3) = 1-\\delta_1-\\delta_2\n",
    "\\end{equation}\n",
    "The probability of having our given data given that we are in a class k is given by:\n",
    "\\begin{equation}\n",
    "y_i|x_i = 1∼Po(\\lambda_1), y_i|x_i = 2∼Po(\\lambda_2), y_i|x_i = 3∼Po(\\lambda_3)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70fab01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = state_seq\n",
    "Y = observation_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd5bc7f",
   "metadata": {},
   "source": [
    "### The E step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf99ea5",
   "metadata": {},
   "source": [
    "Since the complete log-likelihood is unknown, we use the posterior to evaluate the expectation of the complete data log-likelihood.\n",
    "\n",
    "Computes the conditional probability that the hidden state $x_i=1$\n",
    "\\begin{equation}\n",
    "P(X_i = 1 | Y_i = y_i) = \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a52b38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_step(delta,lmbda,data):\n",
    "    # Handling errors\n",
    "    if np.sum(delta)!=1:\n",
    "        raise ValueError('Delta is not a probability distribution (the values dont sum up to 1)')\n",
    "    # Conditional probability of delta given y\n",
    "    delta_prob = 0\n",
    "    for i in range (len(lmbda)):\n",
    "        delta_prob += delta[i] * poisson.pmf(k=data,mu=lmbda[i])    \n",
    "        \n",
    "    # Conditional probability of each class given data\n",
    "    # Probability of mixture 1 to m\n",
    "    prob = []\n",
    "    for i in range (len(lmbda)-1):\n",
    "        prob.append(delta[i] * poisson.pmf(data,lmbda[i])/delta_prob)\n",
    "      \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e089aa",
   "metadata": {},
   "source": [
    "### The M step\n",
    "\n",
    "Updates the probability parameters so that they maximize the expected value of the data log likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d1b7e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_step(prob ,delta, lmbda, data):    \n",
    "    n_i = [] # number of times we expect to see each mixture, from xi = 1 to xi = m\n",
    "    s_i = [] # sum of data points in the indicator components\n",
    "    for i in range(len(lmbda)-1):\n",
    "        n_i.append(np.sum(prob[i]))\n",
    "        s_i.append(np.sum(data*prob[i]))\n",
    "    n_i.append(len(data)-np.sum(n_i))\n",
    "    s_i.append(np.sum(data)-np.sum(s_i))\n",
    "    \n",
    "    \n",
    "    delta = np.asarray(n_i)/len(data)\n",
    "    delta = np.append(delta,1-sum(delta))\n",
    "\n",
    "        \n",
    "    lmbda = np.divide(np.asarray(s_i),np.asarray(n_i))\n",
    "\n",
    "    \n",
    "    \n",
    "    return delta, lmbda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea8b06c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EM_algorithm(delta,lmbda,data,iterations):\n",
    "    prob = 0.\n",
    "    for i in range(iterations):\n",
    "        prob = E_step(delta,lmbda,Y)\n",
    "        delta,lmbda    = M_step(prob, delta,lmbda,Y)\n",
    "        \n",
    "    return delta,lmbda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8384eb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.27716677, 0.59308916, 0.12974408, 0.        ]),\n",
       " array([12.73203817, 19.78158473, 31.62645129]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = observation_seq\n",
    "delta = np.array([0.5,0.4,0.1])\n",
    "lmbda = np.array([10.,20.,30.])\n",
    "EM_algorithm(delta,lmbda, Y, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fac2a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a9f312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685946c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9329096a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "perceived-documentary",
   "metadata": {},
   "source": [
    "Function for a Poisson Maximum Likelihood estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9c8afb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17373533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce63fa87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f96bfba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "tender-coordinator",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-12-228930fc8cd8>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-228930fc8cd8>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "class Poisson_HMM(object):\n",
    "    def __init__(self, states, n_states):\n",
    "        self.x = states\n",
    "        self.m = n_states\n",
    "        \n",
    "    def pn2pw(m,lmbda,gamma,delta=None,stationary=True):\n",
    "        '''natural parameters to working parametes'''\n",
    "        tlambda = np.log(lmbda)\n",
    "        if m == 1:\n",
    "            return tlambda\n",
    "        foo = np.log(gamma/np.diag(gamma))\n",
    "        \n",
    "    def mle(self,x,m,lmbda_ini,delta_ini,stationary):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-alexander",
   "metadata": {},
   "source": [
    "Fit a 2-state Hidden Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-warrior",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 2\n",
    "lmbda_ini = np.array([15,25])\n",
    "gamma_ini = np.array([[0.9,0.1],[0.1,0.9]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
